---
title: "tidysdm workflow functionalities"
output: rmarkdown::html_vignette
#output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{tidysdm overview}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
# set options to limit threads used by imported libraries
options(cores=2)
options(mc.cores=2)
# xgboost uses data.table
data.table::setDTthreads(2)
```

# SDMs with `tidymodels` : an overview of the workflow and functionality

[Intro/Abstract as in paper]

## Background

[intro to tidymodels]

## Workflow with `tidysdm`

### Assembling data - before modelling step

explaining all the pre processing of data;

#### Climate data

In `tidysdm`, environmental raster data are manipulated with [terra](https://cran.r-project.org/package=terra), and it is possible to use any `terra` [SpatRasterDataset](https://rdrr.io/cran/terra/man/sds.html), in which each climatic variable is a `terra` `SpatRaster` with a time dimension.

`tidysdm` is fully integrated with [pastclim](https://evolecolgroup.github.io/pastclim/dev/index.html). This offers several advantages:

-   easy download of environmental data
-   easy manipulation of present-day data, future predictions, and palaeoclimatic reconstructions
-   numerous available [datasets](https://evolecolgroup.github.io/pastclim/articles/a1_available_datasets.html)

#### Species data

##### Download presences

Presences are represented as spatial point objects using the library [sf](#0). All functions in `tidysdm` can work with `sf` objects, and the package extends several methods from the `tidymodels` universe to handle them.

-   introduce the problem that we work with only presences and (sometimes) biased presences

##### Present-day data

Presences can be downloaded from online repositories (e.g GBIF) using packages such as [rgbif](https://cran.r-project.org/package=rgbif) . For an example on how to use `rgbif` see [Example 1](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html).

##### Time-scattered data

Palaeontological/archaeological data that need time series of palaeoclimatic reconstructions can be easily integrated as `tidysdm` does not limit the user to automatically associate points with a single raster. [Example 2](https://evolecolgroup.github.io/tidysdm/articles/a1_palaeodata_application.html) shows how to use time-scattered data based on [horses](https://evolecolgroup.github.io/tidysdm/dev/reference/horses.html) dataset.

Examples of how to use `pastclim` within `tidysdm` to perform SDM both on present-day and time-scattered data can be found in the respective vignettes: [Example 1](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html) and [Example 2](https://evolecolgroup.github.io/tidysdm/articles/a1_palaeodata_application.html).

#### Sample background or pseudo-absences

In most cases, true absences are rarely available. For this reason,Â there are various approaches implemented in `tidysdm` to both sample pseudo-absences and background points.

**Sample background**

The `tidysdm` function `sample_background()` samples background points from a `raster` given a set of presences. The locations returned as the center points of the sampled cells, which can overlap with the presences (in contrast to pseudo-absences).

It provides commonly adopted techniques including:

-   random sampling: the background points are randomly sampled from the region covered by the `raster` (i.e. not NAs),

-   sampling based on maximum distance (`dist_max`): the background points are randomly sampled from the unioned buffers of maximum distance (in meters or map units) from presences. Areas that are in multiple buffers are not over-sampled (i.e. union of buffers or "thickening"),

-   `bias`: background points are sampled according to a surface representing the biased sampling effort.

The `tidysdm` function `sample_background_time()` samples background points from a raster given a set of presences. The locations returned as the center points of the sampled cells, which can overlap with the presences.

It provides commonly adopted techniques including:

-   random sampling;

-   sampling based on maximum distance (`dist_max`);

-   `bias`: background points are sampled according to a surface representing the biased sampling effort. Note that the surface for each time step is normalised to sum to 1, it is possible to affect sampling effort within each time step (`n_per_time_step`).

**Sample pseudo-absences**

The `tidysdm` function `sample_pseudoabs()` samples pseudo-absence points from a `raster` given a set of presences. The locations returned as the center points of the sampled cells, which can not overlap with the presences.

It provides commonly adopted techniques including:

-   random sampling: pseudo-absences randomly sampled from the region covered by the raster (i.e. not NAs)

-   minimum distance (`dist_min`): pseudo-absences randomly sampled from the region excluding a buffer of minimum distance (in meters or map units) from presences,

-   maximum distance (`dist_max`): pseudo-absences randomly sampled from the unioned buffers of maximum distance (in meters or map units) from presences. Areas that are in multiple buffers are not over-sampled (i.e. union of buffers or "thickening"),

-   a disc identified by minimum and maximum distance (`dist_disc`): pseudo-absences randomly sampled from the unioned discs around presences with the two values defining the minimum and maximum distance from presences.

The `tidysdm` function `sample_pseudoabs_time()` samples pseudo-absence points from a raster given a set of presences. The locations returned as the center points of the sampled cells, which can not overlap with the presences.

It provides commonly adopted techniques including:

-   random sampling;

-   sampling based on minimum distance (`dist_min`);

-   sampling based on maximum distance (`dist_max`);

-   a disc identified by minimum and maximum distance (`dist_disc`).

#### Thinning

Once we have a set of presences for a species we need to consider the collection/distribution of this data. Generally, presences are the collation of haphazard efforts, leading to spatial sampling biases. A common solution is to thin the data.

**Cell-level thinning**

The `tidysdm` function `thin_by_cell()` thins a dataset so that only one observation per `raster` cell is retained.

The `tidysdm` function `thin_by_cell_time()` thins a dataset so that only one observation per `raster` cell per time slice is retained. We use a raster with layers as time slices to define the data cube on which thinning is enforced (see details below on how time should be formatted).

**Distance-based thinning**

The `tidysdm` function `thin_by_dist()` thins a dataset so that only observations that have a distance from each other greater than a minimum distance are retained (removing close-by points).

The `tidysdm` function `thin_by_dist_time()` thins a dataset so that only observations that have a distance from each other greater than a minimum distance in space and minimum interval in time are retained.

Further thinning can be achieved by aggregating cells in the raster before thinning, as achieved by setting `agg_fact` \> 1 (aggregation works in a manner equivalent to [`terra::aggregate()`](http://127.0.0.1:43143/help/library/terra/help/aggregate)).

#### Choice of variables

Variables are chosen according to their relevance to the focal species. If information on this is lacking, it is possible to identify informative variables exploring the differences between the distribution of climate values for presences and for background. This is implemented in `tidysdm` as:

-   **violinplot**: the function `plot_pres_vs_bg()` uses violin plots to compare presences and pseudo-absences in their distributions over the variable space, which helps choosing variables for which they differ;

-   a **quantitative approach**: the function `dist_pres_vs_bg()` ranks variables based on the proportional overlap of the respective density plots. For each environmental variable, this function computes the density functions of presences and absences and returns (1-overlap), which is a measure of the distance between the two distributions. Variables with a high distance are good candidates for SDMs, as species occurrences are confined to a subset of the available background.

#### Remove collinear variables

The variables of interest can be pruned for collinearity.\
The `tidysdm` function `filter_collinear` is a **step-wise approach** that allows the user to find a subset of variables that have low collinearity and to set a correlation cutoff. This function offer three methods:

-   a method based on the **greatest mean correlation** (`cor_caret`): this method removes variables with a pairwise correlation above a given cutoff, choosing the variable with the greatest mean correlation; this approach is based on the algorithm in `caret::findCorrelation`;

-   a method based on a **variance inflation factor** `(vif_step)`: this method removes variables with a variance inflation factor above a given cutoff (based on the algorithm in `usdm::vifstep`);

-   a method based on the **largest variance inflation factor** `(vif_cor)`: this method finds, at each step, the pair of variables with the highest correlation above the cutoff and removes the one with the largest *vif* such that all have a correlation below a certain cutoff.

This function provides a sensible set of uncorrelated variables to be used with algorithms such as GLMs and GAMSs, but other such sets will likely exist and might be even better: we recommend that users inspect the variables with care and make decisions based on their biological understanding of the system.

### Pre-processing of models

[rationale for tidymodels: why are we using tidymodels, flexibility of having each step of the analysis under control (and with the option to parallelise for improving computing time) and easily add/chose various methods. ]

Once the presences and pseudo-absences or background have been selected and associated with the climatic variables of interest, modelling is performed with `tidymodels`. This is done through:

1.  creating a workflow fitting different models;

2.  creating datafolds;

3.  tuning the model.

#### 1. Creating workflow

`tidymodels` allows to easily fit different models by defining a **workflow** (a "fixed" framework) that accommodates different `model specification` (changes according to the models that will be used). The **workflow** is created by combining:

-   a `recipe` or formula (i.e. a "preprocessor") to process the data;

-   a `model specification`, which can have a few selected values for the `hyperparameters` (i.e., model parameters that cannot be learned directly by training the dataset and should be defined by the user) or can prescribe their tuning.

To build a `workflow_set` of different models, the `hyperparameters` we want to tune need to be defined. To do so, there are several algorithm available, and additional algorithms can be easily added.

-   **algorithms available**

For the most commonly used models, `tidysdm` automatically chooses the most important parameters:\
- Generalised Linear Model, using `sdm_spec_glm()`,

\- General Additive Model, using `sdm_spec_gam()`,

\- random forest specs with tuning, using `sdm_spec_rf()`,

\- boosted tree model (gbm) specs with tuning, using `sdm_spec_boost_tree()`,

\- maxent specs with tuning, using `sdm_spec_maxent()`

It is possible to fully customise model specifications (e.g. see the help for `sdm_spec_rf()`).

-   **additional algorithms can be added (based on `parsnip`)**

This step uses `workflowsets` (you can find more information [here](https://workflowsets.tidymodels.org/articles/tuning-and-comparing-models.html)).

Further options for tuning or re-sampling can be added to the models using the `workflowsets::option_add()` (see [Example 1](https://evolecolgroup.github.io/tidysdm/articles/a0_tidysdm_overview.html)).

#### 2. Create data folds

Before tuning and assessing the chosen models, `tidysdm` allows us to set up a spatial block cross-validation scheme.

We use the `spatial_block_cv` function from the package `spatialsample`. The function `blockcv2rsample()` convert objects created with `blockCV` into an `rsample` object suitable to `tisysdm`

#### 3. Tune the model

Then, the obtained block CV folds are used to tune and assess the models. We can create combination of hyperparameters per model based on `workflowsets::workflow_map()` and `tidysdm::sdm_metric_set()`.

##### Troubleshooting models that fail

See tutorial [here](https://evolecolgroup.github.io/tidysdm/articles/a3_troubleshooting.html).

### **Evaluation**

The `tidysdm` function `sdm_metric_set()` offers the most commonly used metrics for SDM:

-   Boyce continuous index (BCI), using `boyce_cont()`,

-   Area under the receiver operator curve, using `roc_auc()`,

-   Maximum True Skill Statistics, using `tss_max()`.

Other metrics can be added using `yardstick::metric_set()`. This function allows the user to set options for the metrics (see `help` page).

### **Ensemble**

Then, it is possible to create an **ensemble** selecting the best set of parameters for each model. When adding members to an ensemble, they areautomatically fitted to the full training dataset, and so ready to make predictions.

`tidysdm` offers three options: simple ensemble, stacked ensemble, and repeated ensemble.

**Simple ensemble**

The `tidysdm` function `simple_ensemble()` creates a collection of workflows for which predictions will be combined in a simple way (e.g. by taking either the mean or median). Members are added with `add_best_candidates()`.

Usually these workflows will consists each of the best version of a given model algorithm following tuning. The **workflows** are fitted to the full training dataset before making predictions.

**Repeated ensemble**

As the steps of of thinning and sampling pseudo-absences or background are stochastic and might impact on the performance of SDMs, it is good practice to further explore their effect. In `tidysdm`, the user can repeate the analysis and then create ensembles of models over these repeats through `repeat_ensembles`.

This is done by creating a list of `simple_ensembles`, and then by looping through the SDM pipeline, adding members to the list with `add_member` and finally creating a `repeat_ensemble` from the list with `add_repeat`.

**Stacked ensemble**

Instead of building a simple ensemble with the best version of each model type, it is possible to build a stack ensemble with `stacks()`. Stacking uses a meta-learning algorithm to learn how to best combine multiple models, including multiple versions of the same algorithm with different hyper-parameters (see package `stacks`).

**Ensemble from individual workflows**

**Averaging ensembles**

**Evaluation of ensembles**

### **Projection**

#### Predict

After creating the ensemble, it is possible to make predictions with `predict_raster()`.

The ensemble can be subsetted to only use the best models:

-   the default option takes the mean of the predictions from each model

-   the median of the available model predictions can be obtained

-   it is possible to set a minimum threshold for a chosen metric adding `metric_thresh` to `predict_raster()` (e.g. Boyce continuous index, AUC, TSS).

\- same time slice

\- different time slice

##### Convert into binary

Instead of probability of occurrence, it is also possible to obtain binary predictions (presence vs absence) with `tidysdm`:

-   first need to calibrate the thresholdused to convert probabilities into classes using a metric (e.g. TSS) with `calib_class_thresh()`

-   then, predict again with `predict_raster()`.

#### Compare niche

The `tidysdm` function `niche_overlap()` computes overlap metrics between two `rasters` ([`terra::SpatRaster`](http://127.0.0.1:32097/help/library/terra/help/SpatRaster-class) with a single layer). It currently implements Schoener's D and the inverse I of Hellinger's distance.

#### Managing extrapolation:

\- MESS

\- area of applicability (<https://rdrr.io/cran/waywiser/man/ww_area_of_applicability.html>)

In case of prediction covering areas beyond sampling locations (i.e.Â the new areas may have different properties ), the areas of applicability of the model need to be assessed.

In the `tidymodels` framework it is possible to include methods for assessing models fit to spatial data based on `waywiser::ww_area_of_applicability()` . This includes:

-   assessing models fit

-   measuring the spatial structure of model errors.

\- clamping

It is possible to clamp the predictors to match values in training set with the `tidysdm` function `clamp_predictors()`. This function clamps the environmental variables in a [`terra::SpatRaster`](http://127.0.0.1:32097/help/library/terra/help/SpatRaster-class) or [`terra::SpatRasterDataset`](http://127.0.0.1:32097/help/library/terra/help/SpatRaster-class) so that their minimum and maximum values do not exceed the range in the training dataset.
